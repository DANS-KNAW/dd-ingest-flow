health:
  delayedShutdownHandlerEnabled: false
  initialOverallState: false
  healthChecks:
    - name: Dataverse
      critical: true
      initialState: false
      schedule:
        checkInterval: 60s
    - name: DansBagValidator
      critical: true
      initialState: false
      schedule:
        checkInterval: 60s

#
# Http-interfaces
#
server:
  applicationContextPath: /
  adminContextPath: /
  applicationConnectors:
    - type: http
      port: 20300
  adminConnectors:
    - type: http
      port: 20301

ingestFlow:
  # These target fields are skipped when importing or migrating a dataset. This is useful when for metadata blocks that are active
  # but for which some fields are hidden. Usually you do not want to fill hidden fields. (An exception is the Vault Metadata block.)
  # Fields in metadata blocks that are not active are always skipped.
  skipFields: [ ]

  import:
    # apiKey: # overridden key for the import area
    inbox: /var/opt/dans.knaw.nl/tmp/import/inbox
    outbox: /var/opt/dans.knaw.nl/tmp/import/outbox

  migration:
    # apiKey: # overridden key for the migration area
    inbox: /var/opt/dans.knaw.nl/tmp/migration/deposits
    outbox: /var/opt/dans.knaw.nl/tmp/migration/out

  autoIngest:
    # apiKey: # overridden key for the autoIngest area
    inbox: /var/opt/dans.knaw.nl/tmp/auto-ingest/inbox
    outbox: /var/opt/dans.knaw.nl/tmp/auto-ingest/outbox

    #
    # The following are overrides for the defaults directly below
    #
    depositorRole: swordupdater
    authorization:
      # Required role on the dataverse for the depositor account to publish a SWORD2 created dataset version. Creating a new dataset
      # via SWORD2 does not require a specific role.
      datasetPublisher: swordpublisher
      # Required role on the dataset for the depositor account to create a new version. If the account is datasetPublisher on the dataverse,
      # the new version will be published. Otherwise, the new version will be submitted for review.
      datasetUpdater: swordupdater

  # Default roles required for account to add and update datasets via the ingest-flow. Note that these roles
  # are not always the same as the ones required when working in the user interface! These settings can be overridden in the
  # ingest area configurations above (import, migration, autoIngest).
  #
  # The role that the depositor account will be assigned on its datasets.
  #
  depositorRole: contributorplus
  authorization:
    # Required role on the dataverse for the account to publish a dataset version. Creating a new dataset does not require a specific role.
    # If the implicit group :authenticated-users has this role, this will also suffice.
    # Note that explicit-groups are currently not supported.
    datasetPublisher: dsContributor # Note that dsContributor cannot publish via de user interface.
    # Required role on the dataset for the account to create a new version of dataset. If the account is datasetPublisher on the dataverse,
    # the new version will be published. Otherwise, the new version will be submitted for review.
    datasetUpdater: contributorplus

  #
  # Filtering. Files with a path matching the pattern will not be added to the dataset. Renaming/moving files is not affected.
  #
  fileExclusionPattern: ^$

  #
  # Map from depositor.userId to organization name. Used to fill in the dansDataSupplier metadata field. If there is no
  # entry for a depositor, dansDataSupplier will be left empty.
  #
  dataSuppliers:
  # user001: The Organization Name

  deduplicate: true
  deleteDraftOnFailure: true
  zipWrappingTempDir: /var/opt/dans.knaw.nl/tmp/zip-wrapping
  mappingDefsDir: /etc/opt/dans.knaw.nl/dd-ingest-flow
  taskQueue:
    nameFormat: "ingest-worker-%d"
    maxQueueSize: 5000
    # Number of threads will be increased when maxQueueSize is exceeded.
    minThreads: 2
    # No more than maxThreads will be created though
    maxThreads: 5
    # Threads will die after 60 seconds of idleness
    keepAliveTime: 60 seconds

  vaultMetadataKey: 'changeme' # overrides the default

#
# Parameters related to communication with the Dataverse instance
#
dataverse:
  baseUrl: 'http://localhost:8080'
  apiKey: 'changeme' # define override value per ingest area
  unblockKey: 'changeme'
  awaitLockStateMaxNumberOfRetries: 30
  awaitLockStateMillisecondsBetweenRetries: 500
  httpClient:
    timeout: 30s
    connectionTimeout: 15s
    timeToLive: 1h
    retries: 2

dataverseExtra:
  publishAwaitUnlockMaxRetries: 900
  publishAwaitUnlockWaitTimeMs: 3000

taskEventDatabase:
  driverClass: org.postgresql.Driver
  url: jdbc:postgresql://localhost:5432/dd_ingest_flow
  user: dd_ingest_flow
  password: changeme
  logValidationErrors: true
  properties:
    hibernate.dialect: 'org.hibernate.dialect.PostgreSQL95Dialect'
    hibernate.hbm2ddl.auto: update

validateDansBag:
  baseUrl: 'http://localhost:20330'
  pingUrl: 'http://localhost:20331/ping'
  httpClient:
    timeout: 5min
    connectionTimeout: 1min
    # disable chunked encoding because it breaks the multipart/form-data headers:
    chunkedEncodingEnabled: false
    timeToLive: 1h
    cookiesEnabled: false
    maxConnections: 128
    maxConnectionsPerRoute: 128
    keepAlive: 0ms
    retries: 0
    userAgent: dd-ingest-flow


#
# See https://www.dropwizard.io/en/latest/manual/configuration.html#logging
#
logging:
  level: INFO
  appenders:
    - type: file
      archive: false
      timeZone: system
      currentLogFilename: /var/opt/dans.knaw.nl/log/dd-ingest-flow/dd-ingest-flow.log
  loggers:
    'org.hibernate.engine.internal.StatisticalLoggingSessionEventListener': 'OFF'
